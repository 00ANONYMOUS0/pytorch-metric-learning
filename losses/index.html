



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.dev0, mkdocs-material-4.6.0">
    
    
      
        <title>Losses - PyTorch Metric Learning</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.1b62728e.css">
      
      
    
    
      <script src="../assets/javascripts/modernizr.268332fc.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
    
    
  </head>
  
    <body dir="ltr">
  
    <svg class="md-svg">
      <defs>
        
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#losses" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="PyTorch Metric Learning" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              PyTorch Metric Learning
            </span>
            <span class="md-header-nav__topic">
              
                Losses
              
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main" role="main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="PyTorch Metric Learning" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    PyTorch Metric Learning
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Losses
      </label>
    
    <a href="./" title="Losses" class="md-nav__link md-nav__link--active">
      Losses
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#angularloss" class="md-nav__link">
    AngularLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#arcfaceloss" class="md-nav__link">
    ArcFaceLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basemetriclossfunction" class="md-nav__link">
    BaseMetricLossFunction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#contrastiveloss" class="md-nav__link">
    ContrastiveLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fastaploss" class="md-nav__link">
    FastAPLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#genericpairloss" class="md-nav__link">
    GenericPairLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generalizedliftedstructureloss" class="md-nav__link">
    GeneralizedLiftedStructureLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#marginloss" class="md-nav__link">
    MarginLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multisimilarityloss" class="md-nav__link">
    MultiSimilarityLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ncaloss" class="md-nav__link">
    NCALoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normalizedsoftmaxloss" class="md-nav__link">
    NormalizedSoftmaxLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#npairsloss" class="md-nav__link">
    NPairsLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#proxyncaloss" class="md-nav__link">
    ProxyNCALoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#signaltonoiseratiocontrastiveloss" class="md-nav__link">
    SignalToNoiseRatioContrastiveLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softtripleloss" class="md-nav__link">
    SoftTripleLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tripletmarginloss" class="md-nav__link">
    TripletMarginLoss
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../miners.md" title="Miners" class="md-nav__link">
      Miners
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#angularloss" class="md-nav__link">
    AngularLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#arcfaceloss" class="md-nav__link">
    ArcFaceLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basemetriclossfunction" class="md-nav__link">
    BaseMetricLossFunction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#contrastiveloss" class="md-nav__link">
    ContrastiveLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#fastaploss" class="md-nav__link">
    FastAPLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#genericpairloss" class="md-nav__link">
    GenericPairLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#generalizedliftedstructureloss" class="md-nav__link">
    GeneralizedLiftedStructureLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#marginloss" class="md-nav__link">
    MarginLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#multisimilarityloss" class="md-nav__link">
    MultiSimilarityLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#ncaloss" class="md-nav__link">
    NCALoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#normalizedsoftmaxloss" class="md-nav__link">
    NormalizedSoftmaxLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#npairsloss" class="md-nav__link">
    NPairsLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#proxyncaloss" class="md-nav__link">
    ProxyNCALoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#signaltonoiseratiocontrastiveloss" class="md-nav__link">
    SignalToNoiseRatioContrastiveLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#softtripleloss" class="md-nav__link">
    SoftTripleLoss
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tripletmarginloss" class="md-nav__link">
    TripletMarginLoss
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="losses">Losses</h1>
<p>All loss functions are used as follows:</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">losses</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">SomeLoss</span><span class="p">()</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</pre></div>


<p>Or if you are using a loss in conjunction with a miner:</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_metric_learning</span> <span class="kn">import</span> <span class="n">miners</span><span class="p">,</span> <span class="n">losses</span>
<span class="n">miner_func</span> <span class="o">=</span> <span class="n">miners</span><span class="o">.</span><span class="n">SomeMiner</span><span class="p">()</span>
<span class="n">loss_func</span> <span class="o">=</span> <span class="n">losses</span><span class="o">.</span><span class="n">SomeLoss</span><span class="p">()</span>
<span class="n">miner_output</span> <span class="o">=</span> <span class="n">miner_func</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
<span class="n">losses</span> <span class="o">=</span> <span class="n">loss_func</span><span class="p">(</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">miner_output</span><span class="p">)</span>
</pre></div>


<h2 id="angularloss">AngularLoss</h2>
<p><a href="https://arxiv.org/pdf/1708.01682.pdf">Deep Metric Learning with Angular Loss</a></p>
<div class="codehilite"><pre><span></span><span class="n">losses</span><span class="o">.</span><span class="n">AngularLoss</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">triplets_per_anchor</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>


<p><strong>Parameters</strong>:</p>
<ul>
<li><strong>alpha</strong>: The angle (as described in the paper), specified in degrees.</li>
<li><strong>triplets_per_anchor</strong>: The number of triplets per element to sample within a batch. Can be an integer or the string "all". For example, if your batch size is 128, and triplets_per_anchor is 100, then 12800 triplets will be sampled. If triplets_per_anchor is "all", then all possible triplets in the batch will be used.</li>
</ul>
<h2 id="arcfaceloss">ArcFaceLoss</h2>
<p><a href="https://arxiv.org/pdf/1801.07698.pdf">ArcFace: Additive Angular Margin Loss for Deep Face Recognition</a></p>
<div class="codehilite"><pre><span></span><span class="n">losses</span><span class="o">.</span><span class="n">ArcFaceLoss</span><span class="p">(</span><span class="n">margin</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">,</span> <span class="n">embedding_size</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>


<p><strong>Parameters</strong>:</p>
<ul>
<li><strong>margin</strong>: The angular margin penalty in degrees. </li>
<li><strong>num_classes</strong>: The number of classes in your training dataset.</li>
<li><strong>embedding_size</strong>: The size of the embeddings that you pass into the loss function. For example, if your batch size is 128 and your network outputs 512 dimensional embeddings, then set <em>embedding_size</em> to 512.</li>
<li><strong>scale</strong>: The exponent multiplier in the loss's softmax expression. (This is the inverse of the softmax temperature.)</li>
</ul>
<h2 id="basemetriclossfunction">BaseMetricLossFunction</h2>
<p>All loss functions extend this class.</p>
<div class="codehilite"><pre><span></span><span class="n">losses</span><span class="o">.</span><span class="n">BaseMetricLossFunction</span><span class="p">(</span><span class="n">normalize_embeddings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_class_per_param</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learnable_param_names</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>


<p><strong>Parameters</strong>:</p>
<ul>
<li><strong>normalize_embeddings</strong>: If True, embeddings will be normalized to have a Euclidean norm of 1 before the loss is computed.</li>
<li><strong>num_class_per_param</strong>: If <em>learnable_param_names</em> is set, then this represents the number of classes for each parameter. If your parameters don't have a separate value for each class, then you can leave this at None.</li>
<li><strong>learnable_param_names</strong>: A list of strings where each element is the name of attributes that should be converted to nn.Parameter. If None, then no parameters are converted. </li>
</ul>
<p><strong>Required Implementations</strong>:</p>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">indices_tuple</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>


<h2 id="contrastiveloss">ContrastiveLoss</h2>
<div class="codehilite"><pre><span></span><span class="n">losses</span><span class="o">.</span><span class="n">ContrastiveLoss</span><span class="p">(</span><span class="n">pos_margin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">neg_margin</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">use_similarity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">power</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">avg_non_zero_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</pre></div>


<p><strong>Parameters</strong>:</p>
<ul>
<li><strong>pos_margin</strong>: The distance (or similarity) over (under) which positive pairs will contribute to the loss.</li>
<li><strong>neg_margin</strong>: The distance (or similarity) under (over) which negative pairs will contribute to the loss.  </li>
<li><strong>use_similarity</strong>: If True, will use dot product between vectors instead of euclidean distance.</li>
<li><strong>power</strong>: Each pair's loss will be raised to this power.</li>
<li><strong>avg_non_zero_only</strong>: Only pairs that contribute non-zero loss will be used in the final loss. </li>
</ul>
<h2 id="fastaploss">FastAPLoss</h2>
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.pdf">Deep Metric Learning to Rank</a></p>
<div class="codehilite"><pre><span></span><span class="n">losses</span><span class="o">.</span><span class="n">FastAPLoss</span><span class="p">(</span><span class="n">num_bins</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>


<p><strong>Parameters</strong>:</p>
<ul>
<li><strong>num_bins</strong>: The number of soft histogram bins for calculating average precision</li>
</ul>
<h2 id="genericpairloss">GenericPairLoss</h2>
<div class="codehilite"><pre><span></span><span class="n">losses</span><span class="o">.</span><span class="n">GenericPairLoss</span><span class="p">(</span><span class="n">use_similarity</span><span class="p">,</span> <span class="n">iterate_through_loss</span><span class="p">,</span> <span class="n">squared_distances</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>


<p><strong>Parameters</strong>:</p>
<ul>
<li><strong>use_similarity</strong>: Set to True if the loss function uses pairwise similarity (dot product of each embedding pair). Otherwise, euclidean distance will be used.</li>
<li><strong>iterate_through_loss</strong>: If True, then pairs are passed iteratively to self.pair_based_loss, by going through each sample in a batch, and selecting just the positive and negative pairs containing that sample. Otherwise, the pairs are passed to self.pair_based_loss all at once. </li>
<li><strong>squared_distances</strong>: If True, then the euclidean distance will be squared.</li>
</ul>
<p><strong>Required Implementations</strong>:</p>
<div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">pair_based_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pos_pairs</span><span class="p">,</span> <span class="n">neg_pairs</span><span class="p">,</span> <span class="n">pos_pair_anchor_labels</span><span class="p">,</span> <span class="n">neg_pair_anchor_labels</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>


<h2 id="generalizedliftedstructureloss">GeneralizedLiftedStructureLoss</h2>
<h2 id="marginloss">MarginLoss</h2>
<p><a href="https://arxiv.org/pdf/1706.07567.pdf">Sampling Matters in Deep Embedding Learning</a></p>
<h2 id="multisimilarityloss">MultiSimilarityLoss</h2>
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Multi-Similarity Loss with General Pair Weighting for Deep Metric Learning</a></p>
<h2 id="ncaloss">NCALoss</h2>
<p>Neighbourhood Components Analysis](https://www.cs.toronto.edu/~hinton/absps/nca.pdf)</p>
<h2 id="normalizedsoftmaxloss">NormalizedSoftmaxLoss</h2>
<p><a href="https://arxiv.org/pdf/1811.12649.pdf">Classification is a Strong Baseline for DeepMetric Learning</a></p>
<h2 id="npairsloss">NPairsLoss</h2>
<p><a href="http://www.nec-labs.com/uploads/images/Department-Images/MediaAnalytics/papers/nips16_npairmetriclearning.pdf">Improved Deep Metric Learning with Multi-class N-pair Loss Objective</a></p>
<h2 id="proxyncaloss">ProxyNCALoss</h2>
<p><a href="https://arxiv.org/pdf/1703.07464.pdf">No Fuss Distance Metric Learning using Proxies</a></p>
<h2 id="signaltonoiseratiocontrastiveloss">SignalToNoiseRatioContrastiveLoss</h2>
<p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.pdf">Signal-to-Noise Ratio: A Robust Distance Metric for Deep Metric Learning</a></p>
<h2 id="softtripleloss">SoftTripleLoss</h2>
<p><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Qian_SoftTriple_Loss_Deep_Metric_Learning_Without_Triplet_Sampling_ICCV_2019_paper.pdf">SoftTriple Loss: Deep Metric Learning Without Triplet Sampling</a></p>
<h2 id="tripletmarginloss">TripletMarginLoss</h2>
                
                  
                
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href=".." title="Home" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Home
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.808e90bb.js"></script>
      
      <script>app.initialize({version:"1.1.dev0",url:{base:".."}})</script>
      
    
  </body>
</html>